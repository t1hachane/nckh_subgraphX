{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66d2dc1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T09:18:18.800083Z",
     "iopub.status.busy": "2024-07-25T09:18:18.799553Z",
     "iopub.status.idle": "2024-07-25T09:18:19.788859Z",
     "shell.execute_reply": "2024-07-25T09:18:19.787658Z"
    },
    "papermill": {
     "duration": 1.005422,
     "end_time": "2024-07-25T09:18:19.791830",
     "exception": false,
     "start_time": "2024-07-25T09:18:18.786408",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "dict_omic_id = {1: \"Gene expression lv3\",\n",
    "                2: \"CNV threshold\",\n",
    "                3: \"DNA Methylation 27\",\n",
    "#                 3: \"miRNA\"\n",
    "               }\n",
    "\n",
    "dict_file_name = {1: \"GE\",\n",
    "                  2: \"CNA\",\n",
    "                  3: \"Meth\",\n",
    "#                   3: \"miRNA\"\n",
    "                 }\n",
    "\n",
    "# input_raw_dir = '/kaggle/input/xena-luad'\n",
    "\n",
    "# omic_data_dir = {\n",
    "#     1: f\"{input_raw_dir}/HiSeqV2\",\n",
    "# #     2: f\"{input_raw_dir}/Gistic2_CopyNumber_Gistic2_all_thresholded.by_genes\",\n",
    "#     2: f\"{input_raw_dir}/HumanMethylation450\",\n",
    "#     3: f\"{input_raw_dir}/miRNA_HiSeq_gene\"\n",
    "# }\n",
    "\n",
    "input_raw_dir = '/kaggle/input/xena-gbm'\n",
    "\n",
    "omic_data_dir = {\n",
    "    1: f\"{input_raw_dir}/HT_HG-U133A\",\n",
    "    2: f\"{input_raw_dir}/Gistic2_CopyNumber_Gistic2_all_thresholded.by_genes\",\n",
    "    3: f\"{input_raw_dir}/HumanMethylation27\"\n",
    "}\n",
    "\n",
    "subtype_dir = f\"{input_raw_dir}/TCGA.GBM.sampleMap_GBM_clinicalMatrix\"\n",
    "subtype_col_name = 'GeneExp_Subtype'\n",
    "# subtype_dir = f\"{input_raw_dir}/TCGASubtype.20170308.tsv\"\n",
    "# subtype_col_name = 'Subtype_other'\n",
    "# subtype_dir = f\"{input_raw_dir}/TCGA.LUAD.sampleMap_LUAD_clinicalMatrix\"\n",
    "# subtype_col_name = 'Expression_Subtype'\n",
    "\n",
    "CpG_sites_dir = f\"{input_raw_dir}/illumina_humanmethylation27_content.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccb8c1ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T09:18:19.816136Z",
     "iopub.status.busy": "2024-07-25T09:18:19.815556Z",
     "iopub.status.idle": "2024-07-25T09:18:19.824843Z",
     "shell.execute_reply": "2024-07-25T09:18:19.823618Z"
    },
    "papermill": {
     "duration": 0.02457,
     "end_time": "2024-07-25T09:18:19.827439",
     "exception": false,
     "start_time": "2024-07-25T09:18:19.802869",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_csv_file(file_path, transpose=False):\n",
    "    # Reading the data into a pandas DataFrame\n",
    "    # Warning: DtypeWarning\n",
    "    data = pd.read_csv(file_path, sep=\"\\t\", header=None, low_memory=False)\n",
    "\n",
    "    # Transposing the DataFrame if transpose is True\n",
    "    if transpose:\n",
    "        data = data.transpose()\n",
    "        data.dropna(axis=1, inplace=True)\n",
    "\n",
    "    data.columns = data.iloc[0]\n",
    "    # data = data.iloc[1:]\n",
    "    data = data.drop(0)\n",
    "\n",
    "    return data\n",
    "\n",
    "def read_xlxs_file(file_path):\n",
    "    data = pd.read_excel(file_path, header=None)\n",
    "    data.columns = data.iloc[0]\n",
    "    data = data.drop(0)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c80d49a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T09:18:19.851011Z",
     "iopub.status.busy": "2024-07-25T09:18:19.850583Z",
     "iopub.status.idle": "2024-07-25T09:18:19.857384Z",
     "shell.execute_reply": "2024-07-25T09:18:19.856276Z"
    },
    "papermill": {
     "duration": 0.021799,
     "end_time": "2024-07-25T09:18:19.859935",
     "exception": false,
     "start_time": "2024-07-25T09:18:19.838136",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inner_join_subtypes(subtype_data, df, str_df):\n",
    "    merged_df = pd.merge(\n",
    "        subtype_data[[\"sampleID\", subtype_col_name]],\n",
    "        df,\n",
    "        left_on=\"sampleID\",\n",
    "        right_on=str_df,\n",
    "        how=\"inner\",\n",
    "    )\n",
    "\n",
    "    # Drop the duplicate \"sampleID\" column\n",
    "    merged_df.drop(str_df, axis=1, inplace=True)\n",
    "\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fa5c3e",
   "metadata": {
    "papermill": {
     "duration": 0.010727,
     "end_time": "2024-07-25T09:18:19.881493",
     "exception": false,
     "start_time": "2024-07-25T09:18:19.870766",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **STEP 1:** GET SUBTYPES AND OMIC DATAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3286595",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T09:18:19.904713Z",
     "iopub.status.busy": "2024-07-25T09:18:19.904322Z",
     "iopub.status.idle": "2024-07-25T09:18:19.983866Z",
     "shell.execute_reply": "2024-07-25T09:18:19.982398Z"
    },
    "papermill": {
     "duration": 0.094799,
     "end_time": "2024-07-25T09:18:19.986933",
     "exception": false,
     "start_time": "2024-07-25T09:18:19.892134",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "subtype_data = read_csv_file(subtype_dir)[[\"sampleID\", subtype_col_name]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e21f42ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T09:18:20.010624Z",
     "iopub.status.busy": "2024-07-25T09:18:20.010216Z",
     "iopub.status.idle": "2024-07-25T09:18:20.017116Z",
     "shell.execute_reply": "2024-07-25T09:18:20.015608Z"
    },
    "papermill": {
     "duration": 0.022561,
     "end_time": "2024-07-25T09:18:20.020261",
     "exception": false,
     "start_time": "2024-07-25T09:18:19.997700",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# concerned_subtypes = {\n",
    "# # # STAD\n",
    "# #               'CIN': 'CIN',\n",
    "# #               'EBV': 'EBV',\n",
    "# #               'GS': 'GS',\n",
    "# #               'HM-SNV': 'HM',\n",
    "# #               'HM-indel': 'HM',\n",
    "                      \n",
    "# # # SARC\n",
    "# #               'Dedifferentiated liposarcoma': 'DDLPS',\n",
    "# #               'Leiomyosarcoma (LMS)': 'LMS',\n",
    "# #               'Myxofibrosarcoma': 'MFS',\n",
    "# #               'Pleomorphic MFH / Undifferentiated pleomorphic sarcoma': 'UPS', \n",
    "# #               'Synovial Sarcoma - Biphasic': 'SS', \n",
    "# #               'Synovial Sarcoma - Monophasic': 'SS', \n",
    "# #               'Undifferentiated Pleomorphic Sarcoma (UPS)': 'UPS', \n",
    "# #               'Sarcoma; synovial; poorly differentiated': 'SS', \n",
    "# #               'Giant cell MFH / Undifferentiated pleomorphic sarcoma with giant cells': 'UPS', \n",
    "# #               'Malignant Peripheral Nerve Sheath Tumors (MPNST)': 'MPNST', \n",
    "# #               'Desmoid Tumor': 'DT'\n",
    "#              }\n",
    "# subtype_data[subtype_col_name] = subtype_data[subtype_col_name].apply(lambda x: concerned_subtypes.get(x, np.nan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5c2d266",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T09:18:20.044275Z",
     "iopub.status.busy": "2024-07-25T09:18:20.043817Z",
     "iopub.status.idle": "2024-07-25T09:18:20.057370Z",
     "shell.execute_reply": "2024-07-25T09:18:20.055759Z"
    },
    "papermill": {
     "duration": 0.028599,
     "end_time": "2024-07-25T09:18:20.060303",
     "exception": false,
     "start_time": "2024-07-25T09:18:20.031704",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Classical' 'Neural' 'Proneural' 'Mesenchymal']\n"
     ]
    }
   ],
   "source": [
    "subtype_data = subtype_data.dropna(subset=[subtype_col_name])\n",
    "print(subtype_data[subtype_col_name].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89dfdae7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T09:18:20.084667Z",
     "iopub.status.busy": "2024-07-25T09:18:20.084164Z",
     "iopub.status.idle": "2024-07-25T09:18:42.826846Z",
     "shell.execute_reply": "2024-07-25T09:18:42.825621Z"
    },
    "papermill": {
     "duration": 22.758176,
     "end_time": "2024-07-25T09:18:42.829861",
     "exception": false,
     "start_time": "2024-07-25T09:18:20.071685",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Omic data Gene expression lv3: (539, 12043)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Omic data CNV threshold: (577, 24777)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Omic data DNA Methylation 27: (288, 22978)\n"
     ]
    }
   ],
   "source": [
    "omic_data = {}\n",
    "unlabeled_omic_data = {}\n",
    "sample_str = {\n",
    "    1: \"sample\",\n",
    "    2: \"Gene Symbol\",\n",
    "#     2: \"sample\",\n",
    "    3: \"sample\",\n",
    "}\n",
    "\n",
    "for omic_id in dict_omic_id.keys():\n",
    "\n",
    "    data = read_csv_file(omic_data_dir[omic_id], transpose=True)\n",
    "    data.rename(columns={sample_str[omic_id]: \"sampleID\"}, inplace=True)\n",
    "\n",
    "    omic_data[omic_id] = data\n",
    "\n",
    "    print(f\"Omic data {dict_omic_id[omic_id]}: {omic_data[omic_id].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4756a09c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T09:18:42.854281Z",
     "iopub.status.busy": "2024-07-25T09:18:42.853847Z",
     "iopub.status.idle": "2024-07-25T09:19:00.349180Z",
     "shell.execute_reply": "2024-07-25T09:19:00.348045Z"
    },
    "papermill": {
     "duration": 17.511139,
     "end_time": "2024-07-25T09:19:00.352290",
     "exception": false,
     "start_time": "2024-07-25T09:18:42.841151",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CpG site to GeneID mapping DNA methylation\n",
    "df2 = read_xlxs_file(CpG_sites_dir)[[\"Name\", \"Symbol\"]]\n",
    "df2 = df2.dropna(subset=[\"Name\", \"Symbol\"])\n",
    "cpg_site_mapping = dict(zip(df2[\"Name\"], df2[\"Symbol\"] + \"|\" + df2[\"Name\"]))\n",
    "\n",
    "for omic_id, omic_name in dict_omic_id.items():\n",
    "    if \"Methylation\" in omic_name:\n",
    "        # print(f\"Omic data {omic_name} before mapping: {omic_data[omic_id].shape}\")\n",
    "        omic_data[omic_id] = omic_data[omic_id].rename(columns=cpg_site_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c44b055",
   "metadata": {
    "papermill": {
     "duration": 0.010847,
     "end_time": "2024-07-25T09:19:00.374282",
     "exception": false,
     "start_time": "2024-07-25T09:19:00.363435",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **STEP 2:** Get common samples of omic datas. Label them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca4048b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T09:19:00.398819Z",
     "iopub.status.busy": "2024-07-25T09:19:00.398297Z",
     "iopub.status.idle": "2024-07-25T09:19:00.411035Z",
     "shell.execute_reply": "2024-07-25T09:19:00.409711Z"
    },
    "papermill": {
     "duration": 0.027817,
     "end_time": "2024-07-25T09:19:00.413763",
     "exception": false,
     "start_time": "2024-07-25T09:19:00.385946",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_common_samples(omic_data):\n",
    "    # Bước 1: Lấy cột sampleID từ subtype_data\n",
    "    common_samples = subtype_data[[\"sampleID\", subtype_col_name]].copy()\n",
    "    \n",
    "    # Bước 2: Tìm giao của tất cả sampleID\n",
    "    common_ids = set(common_samples[\"sampleID\"])\n",
    "    for key, df in omic_data.items():\n",
    "        common_ids &= set(df[\"sampleID\"])\n",
    "\n",
    "    # Tạo DataFrame với các common_ids\n",
    "    common_samples = common_samples[common_samples[\"sampleID\"].isin(common_ids)]\n",
    "    common_samples.sort_values(\"sampleID\", inplace=True)\n",
    "    common_samples.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    print(f\"Common samples: {common_samples.shape[0]}\")\n",
    "    print(\"Shape of omic data: \")\n",
    "\n",
    "    for key, df in omic_data.items():\n",
    "        # Lọc các hàng theo common_ids\n",
    "        df_filtered = df[df[\"sampleID\"].isin(common_ids)].copy()\n",
    "        df_filtered.sort_values(\"sampleID\", inplace=True)\n",
    "        df_filtered.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        unlabeled_omic_data[key] = df[~df[\"sampleID\"].isin(common_ids)].copy()\n",
    "        unlabeled_omic_data[key].sort_values(\"sampleID\", inplace=True)\n",
    "        unlabeled_omic_data[key].reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        omic_data[key] = df_filtered\n",
    "        print(f\"{key}: {omic_data[key].shape}, {unlabeled_omic_data[key].shape}\")\n",
    "\n",
    "    # Kiểm tra lại các sampleID chung\n",
    "    for df in omic_data.values():\n",
    "        if not df[\"sampleID\"].equals(common_samples[\"sampleID\"]):\n",
    "            print(\"Error: Common samples are not equal\")\n",
    "\n",
    "    return common_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb77c94d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T09:19:00.439120Z",
     "iopub.status.busy": "2024-07-25T09:19:00.438691Z",
     "iopub.status.idle": "2024-07-25T09:19:02.968393Z",
     "shell.execute_reply": "2024-07-25T09:19:02.967075Z"
    },
    "papermill": {
     "duration": 2.54642,
     "end_time": "2024-07-25T09:19:02.971444",
     "exception": false,
     "start_time": "2024-07-25T09:19:00.425024",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common samples: 270\n",
      "Shape of omic data: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: (270, 12043), (269, 12043)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2: (270, 24777), (307, 24777)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3: (270, 22978), (18, 22978)\n"
     ]
    }
   ],
   "source": [
    "common_samples_df = get_common_samples(omic_data)\n",
    "common_samples_array = common_samples_df[\"sampleID\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fc29a54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T09:19:02.995945Z",
     "iopub.status.busy": "2024-07-25T09:19:02.995528Z",
     "iopub.status.idle": "2024-07-25T09:19:03.002247Z",
     "shell.execute_reply": "2024-07-25T09:19:03.001052Z"
    },
    "papermill": {
     "duration": 0.02223,
     "end_time": "2024-07-25T09:19:03.004957",
     "exception": false,
     "start_time": "2024-07-25T09:19:02.982727",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Classical' 'Proneural' 'Proneural' 'Classical' 'Proneural' 'Proneural'\n",
      " 'Proneural' 'Classical' 'Proneural' 'Classical']\n"
     ]
    }
   ],
   "source": [
    "labels_array = common_samples_df[subtype_col_name].to_numpy()\n",
    "print(labels_array[:10])\n",
    "# labels_array = np.vectorize(map_label1.get)(labels_array)\n",
    "# print(labels_array)\n",
    "# print(map_label)\n",
    "# print(\"Labels: \", labels_array.shape)\n",
    "# print(\"Labels: \", labels_array[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e73394b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T09:19:03.030038Z",
     "iopub.status.busy": "2024-07-25T09:19:03.029564Z",
     "iopub.status.idle": "2024-07-25T09:19:03.038204Z",
     "shell.execute_reply": "2024-07-25T09:19:03.037060Z"
    },
    "papermill": {
     "duration": 0.024214,
     "end_time": "2024-07-25T09:19:03.040897",
     "exception": false,
     "start_time": "2024-07-25T09:19:03.016683",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Classical': 1, 'Mesenchymal': 2, 'Neural': 3, 'Proneural': 4}\n",
      "Labels:  (270,)\n",
      "Labels:  [1 4 4 1 4 4 4 1 4 1 4 2 2 1 1 4 4 3 2 3]\n"
     ]
    }
   ],
   "source": [
    "# Map labels_array to integer\n",
    "# map_label = {\"Classical\": 0, \"Neural\": 1, \"Proneural\": 2, \"Mesenchymal\": 3}\n",
    "map_label = {key: index + 1 for index, key in enumerate(np.unique(labels_array))}\n",
    "labels_array = np.vectorize(map_label.get)(labels_array)\n",
    "print(map_label)\n",
    "print(\"Labels: \", labels_array.shape)\n",
    "print(\"Labels: \", labels_array[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c09e9cb",
   "metadata": {
    "papermill": {
     "duration": 0.01198,
     "end_time": "2024-07-25T09:19:03.064556",
     "exception": false,
     "start_time": "2024-07-25T09:19:03.052576",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **STEP 3:** Get common samples in omic datas. Add Label to omics data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e07e408",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T09:19:03.091154Z",
     "iopub.status.busy": "2024-07-25T09:19:03.090670Z",
     "iopub.status.idle": "2024-07-25T09:19:03.102403Z",
     "shell.execute_reply": "2024-07-25T09:19:03.101154Z"
    },
    "papermill": {
     "duration": 0.027767,
     "end_time": "2024-07-25T09:19:03.105278",
     "exception": false,
     "start_time": "2024-07-25T09:19:03.077511",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of samples after isin:\n",
      "(270, 12044)\n",
      "(270, 24778)\n",
      "(270, 22979)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of samples after isin:\")\n",
    "for key, df in omic_data.items():\n",
    "#     # Bỏ các cột có ít nhất một giá trị nan\n",
    "#     selected_columns = []\n",
    "#     for i, column in enumerate(df.columns):\n",
    "#         if df[column].isnull().values.any():\n",
    "#             continue\n",
    "#         selected_columns.append(i)\n",
    "\n",
    "#     omic_data[key] = df.iloc[:, selected_columns]\n",
    "    omic_data[key].insert(1, subtype_col_name, labels_array, )\n",
    "    print(omic_data[key].shape)\n",
    "    # print(omic_data[key].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9cd7872",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T09:19:03.130645Z",
     "iopub.status.busy": "2024-07-25T09:19:03.130240Z",
     "iopub.status.idle": "2024-07-25T09:19:03.163782Z",
     "shell.execute_reply": "2024-07-25T09:19:03.162414Z"
    },
    "papermill": {
     "duration": 0.049894,
     "end_time": "2024-07-25T09:19:03.166970",
     "exception": false,
     "start_time": "2024-07-25T09:19:03.117076",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Omic data Gene expression lv3:\n",
      "(270, 12044)\n",
      "0         sampleID  GeneExp_Subtype             RNF14            UBE2Q1  \\\n",
      "0  TCGA-02-0001-01                1  6.49791955133042  8.49434620281726   \n",
      "1  TCGA-02-0003-01                4  6.84261390916503  9.61918147566407   \n",
      "2  TCGA-02-0007-01                4  6.47919385070934  10.0666908297196   \n",
      "3  TCGA-02-0009-01                1  7.21399161939877  9.29024304653481   \n",
      "4  TCGA-02-0010-01                4   7.2000207793856  9.57749740336243   \n",
      "\n",
      "0             RNF17  \n",
      "0  4.81908126516905  \n",
      "1   4.6079529999682  \n",
      "2  4.62369766743086  \n",
      "3  4.44427585272261  \n",
      "4  4.52320574349238  \n",
      "\n",
      "Omic data CNV threshold:\n",
      "(270, 24778)\n",
      "0         sampleID  GeneExp_Subtype ACAP3 ACTRT2 AGRN\n",
      "0  TCGA-02-0001-01                1     1      1    1\n",
      "1  TCGA-02-0003-01                4     0      0    0\n",
      "2  TCGA-02-0007-01                4     0      0    0\n",
      "3  TCGA-02-0009-01                1     0      0    0\n",
      "4  TCGA-02-0010-01                4     0      0    0\n",
      "\n",
      "Omic data DNA Methylation 27:\n",
      "(270, 22979)\n",
      "0         sampleID  GeneExp_Subtype MEOX2|cg00003994 HOXD3|cg00005847  \\\n",
      "0  TCGA-02-0001-01                1           0.0415           0.3819   \n",
      "1  TCGA-02-0003-01                4           0.1039           0.8516   \n",
      "2  TCGA-02-0007-01                4           0.0255           0.4042   \n",
      "3  TCGA-02-0009-01                1           0.0413           0.6353   \n",
      "4  TCGA-02-0010-01                4           0.0373           0.8763   \n",
      "\n",
      "0 PANX1|cg00007981  \n",
      "0           0.0378  \n",
      "1           0.0506  \n",
      "2           0.0510  \n",
      "3           0.0370  \n",
      "4           0.0197  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for omic_id, omic_name in dict_omic_id.items():\n",
    "    print(f\"Omic data {dict_omic_id[omic_id]}:\")\n",
    "    print(omic_data[omic_id].shape)\n",
    "    print(omic_data[omic_id].iloc[:5, :5])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0b9c692",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T09:19:03.193137Z",
     "iopub.status.busy": "2024-07-25T09:19:03.192704Z",
     "iopub.status.idle": "2024-07-25T09:19:03.643433Z",
     "shell.execute_reply": "2024-07-25T09:19:03.642383Z"
    },
    "papermill": {
     "duration": 0.467642,
     "end_time": "2024-07-25T09:19:03.646473",
     "exception": false,
     "start_time": "2024-07-25T09:19:03.178831",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_raw_dir = '/kaggle/working/raw_tcga_luad'\n",
    "os.makedirs(save_raw_dir, exist_ok=True)\n",
    "common_samples_df = common_samples_df.rename(columns={subtype_col_name: \"disease_subtypes\"})\n",
    "#common_samples_df.to_csv(f\"{save_raw_dir}/df_labeled.csv\", index=False)\n",
    "for key in dict_file_name.keys():\n",
    "    omic_data[key] = omic_data[key].drop(subtype_col_name, axis=1)\n",
    "    #omic_data[key].to_csv(f\"{save_raw_dir}/df_{dict_file_name[key]}_labeled.csv\", index=False)\n",
    "    unlabeled_omic_data[key] = unlabeled_omic_data[key] #.drop(subtype_col_name, axis=1)\n",
    "    #unlabeled_omic_data[key].to_csv(f\"{save_raw_dir}/df_{dict_file_name[key]}_unlabeled.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfebda0f",
   "metadata": {
    "papermill": {
     "duration": 0.012005,
     "end_time": "2024-07-25T09:19:03.670271",
     "exception": false,
     "start_time": "2024-07-25T09:19:03.658266",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Code anh Hoang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1748d18a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T09:19:03.697472Z",
     "iopub.status.busy": "2024-07-25T09:19:03.697037Z",
     "iopub.status.idle": "2024-07-25T09:19:05.180912Z",
     "shell.execute_reply": "2024-07-25T09:19:05.179535Z"
    },
    "papermill": {
     "duration": 1.501305,
     "end_time": "2024-07-25T09:19:05.184154",
     "exception": false,
     "start_time": "2024-07-25T09:19:03.682849",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "RANDOM_STATE_1 = 42\n",
    "RANDOM_STATE_2 = 42\n",
    "\n",
    "dct_var_threshold = {'GE': 0.01,\n",
    "                     'CNA': 0.1,\n",
    "                     'Meth' : 0.001,\n",
    "#                      'miRNA': 0.1\n",
    "                    }\n",
    "dct_pre_selection_top = {'GE': 2000,\n",
    "                         'CNA': 2000,\n",
    "                         'Meth' : 2000,\n",
    "#                          'miRNA': 2000\n",
    "                        }\n",
    "# dct_pre_selection_top['GE'] = None  # only do variance filtering\n",
    "# dct_pre_selection_top['CNA'] = None # only do variance filtering\n",
    "\n",
    "dct_adjusted_p_value_threshold = {'GE': 0.05,\n",
    "                                  'CNA': 0.05,\n",
    "                                  'Meth' : 0.05,\n",
    "#                                   'miRNA': 0.05\n",
    "                                 }\n",
    "\n",
    "pca_exp_var_first_comp_cond = 0.5\n",
    "\n",
    "type_scale = 'min_max_0_1'\n",
    "# type_scale = 'z_scaler'\n",
    "scaler = StandardScaler() if type_scale == 'z_scaler' else MinMaxScaler((0,1)) if type_scale == 'min_max_0_1' else None\n",
    "\n",
    "dict_bool_scale = {'GE': True,\n",
    "                   'CNA': False,\n",
    "                   'Meth': True,\n",
    "#                    'miRNA': True\n",
    "                  } # apply scaler or not\n",
    "\n",
    "n_folds = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "faa8a7b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T09:19:05.210505Z",
     "iopub.status.busy": "2024-07-25T09:19:05.210059Z",
     "iopub.status.idle": "2024-07-25T09:19:55.726597Z",
     "shell.execute_reply": "2024-07-25T09:19:55.725383Z"
    },
    "papermill": {
     "duration": 50.533077,
     "end_time": "2024-07-25T09:19:55.729558",
     "exception": false,
     "start_time": "2024-07-25T09:19:05.196481",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "default_dir = save_raw_dir\n",
    "lst_cohort = ['TCGA_GBM']\n",
    "lst_omics = ['GE',\n",
    "             'CNA',\n",
    "             'Meth',\n",
    "#              'miRNA'\n",
    "            ]\n",
    "dict_id_omics = {idx+1: omic for idx, omic in enumerate(lst_omics)}\n",
    "\n",
    "lst_dataset = ['train', 'val', 'test']\n",
    "\n",
    "dct_df= {}\n",
    "unlabeled = {}\n",
    "\n",
    "for cohort in lst_cohort:\n",
    "#     print(f'Cohort: {cohort}')\n",
    "    dir_cohort = f'{default_dir}/'\n",
    "    \n",
    "    dct_df[cohort] = {\n",
    "        'labeled': common_samples_df.set_index('sampleID'), #.apply(pd.to_numeric, errors='coerce'),\n",
    "    }\n",
    "    \n",
    "    unlabeled[cohort] = {}   \n",
    "    \n",
    "    for key, value in dict_file_name.items():\n",
    "        dct_df[cohort][value] = omic_data[key].set_index('sampleID').apply(pd.to_numeric, errors='coerce')\n",
    "        unlabeled[cohort][value] = unlabeled_omic_data[key].set_index('sampleID').apply(pd.to_numeric, errors='coerce')\n",
    "    \n",
    "#     for df in dct_df[cohort].values():\n",
    "#         print(df.iloc[0, 0])\n",
    "    common_samples_df = None\n",
    "    for key in dict_file_name.keys():\n",
    "        omic_data[key] = None\n",
    "        unlabeled_omic_data[key] = None\n",
    "#     lst_data_name = ['labeled'] + lst_omics\n",
    "#     lst_data_csv_name = ['df_labeled'] + [f'df_{omic}_labeled' for omic in lst_omics]\n",
    "#     for data_name, data_csv_name in zip(lst_data_name, lst_data_csv_name):\n",
    "#         loc_data_csv = dir_cohort + f'{data_csv_name}.csv'\n",
    "#         print(f'\\t{data_name}: {loc_data_csv}')\n",
    "#         dct_df[cohort][data_name] = pd.read_csv(loc_data_csv)\n",
    "#         dct_df[cohort][data_name] = dct_df[cohort][data_name].set_index('sampleID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8bdbdb13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T09:19:55.758094Z",
     "iopub.status.busy": "2024-07-25T09:19:55.756502Z",
     "iopub.status.idle": "2024-07-25T09:19:55.767507Z",
     "shell.execute_reply": "2024-07-25T09:19:55.765340Z"
    },
    "papermill": {
     "duration": 0.029472,
     "end_time": "2024-07-25T09:19:55.771052",
     "exception": false,
     "start_time": "2024-07-25T09:19:55.741580",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohort: TCGA_GBM\n",
      "Sample IDs are consistent between GE and CNA\n",
      "Sample IDs are consistent between CNA and Meth\n"
     ]
    }
   ],
   "source": [
    "for cohort in lst_cohort:\n",
    "    print(f'Cohort: {cohort}')\n",
    "    for omic_idx, omic in enumerate(lst_omics):\n",
    "        if omic_idx < len(lst_omics)-1:\n",
    "            assert (dct_df[cohort][lst_omics[omic_idx]].index == dct_df[cohort][lst_omics[omic_idx+1]].index).all(), \\\n",
    "            f'Sample IDs are NOT consistent between {omic} and {lst_omics[omic_idx+1]}'\n",
    "            print(f'Sample IDs are consistent between {omic} and {lst_omics[omic_idx+1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5590461e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T09:19:55.799086Z",
     "iopub.status.busy": "2024-07-25T09:19:55.798168Z",
     "iopub.status.idle": "2024-07-25T09:19:55.823609Z",
     "shell.execute_reply": "2024-07-25T09:19:55.822300Z"
    },
    "papermill": {
     "duration": 0.04241,
     "end_time": "2024-07-25T09:19:55.826463",
     "exception": false,
     "start_time": "2024-07-25T09:19:55.784053",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(dct_df[cohort]['GE'].min() < 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ffe28635",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T09:19:55.854818Z",
     "iopub.status.busy": "2024-07-25T09:19:55.854361Z",
     "iopub.status.idle": "2024-07-25T09:19:56.210560Z",
     "shell.execute_reply": "2024-07-25T09:19:56.209067Z"
    },
    "papermill": {
     "duration": 0.374245,
     "end_time": "2024-07-25T09:19:56.214058",
     "exception": false,
     "start_time": "2024-07-25T09:19:55.839813",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "def get_indices_feat_sel_var_threshold(X, threshold=0):\n",
    "    sel = VarianceThreshold(threshold)\n",
    "    sel.fit(X)\n",
    "    bool_sels = sel.get_support()\n",
    "    lst_indices_sels = [idx for idx, bool_val in enumerate(bool_sels) if bool_val]\n",
    "    return lst_indices_sels\n",
    "\n",
    "\n",
    "from sklearn.feature_selection import SelectFdr, f_classif\n",
    "def get_indices_feat_sel_fdr_anova_fval_alpha(X, y, adjusted_p_value_threshold=0.05, top_k_score=None):\n",
    "    sel = SelectFdr(score_func=f_classif, alpha=adjusted_p_value_threshold)\n",
    "    sel.fit(X, y)\n",
    "    \n",
    "    bool_sels = sel.get_support()\n",
    "    \n",
    "    # smaller p-value is better\n",
    "    # first filter by adjusted_pvalue threshold \n",
    "    lst_indices_sels = [idx for idx, bool_val in enumerate(bool_sels) if bool_val]\n",
    "    \n",
    "    # also bigger f_statistic score is better\n",
    "    # second get top by f_statistic\n",
    "    f_statistic = sel.scores_    \n",
    "    f_statistic_asc_indices = np.argsort(f_statistic)\n",
    "    f_statistic_desc_indices = f_statistic_asc_indices[::-1]\n",
    "    # # exclude idx feat that excluded before by adjusted p value threshold\n",
    "    \n",
    "    f_statistic_desc_indices = [idx for idx in f_statistic_desc_indices if idx in lst_indices_sels] \n",
    "    \n",
    "    # if not defined top_k_score (=None) then get all features == not selected by top k score f statistic\n",
    "    top_k_score = top_k_score if top_k_score is not None else len(f_statistic_desc_indices)\n",
    "    top_idx_by_score = f_statistic_desc_indices[:top_k_score]\n",
    "    \n",
    "    return top_idx_by_score\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "\n",
    "def bool_check_exp_var_first_comp_cond(X, threshold=0.5, n_components=None, batch_size=1000):\n",
    "    \"\"\"\n",
    "        for each classification task, ANOVA F-value was calculated sequentially\n",
    "        using the training data to evaluate whether a feature was significantly\n",
    "        different across different classes, where FDR controlling procedures were\n",
    "        applied for multiple-testing compensation. \n",
    "        However, selecting too few features might also result in only selecting\n",
    "        highly correlated features, which could potentially restrain the models\n",
    "        from taking advantage of complementary information from diverse features.\n",
    "        To avoid this situation, we determined the number of preselected features\n",
    "        for each omics data type with an additional rule, i.e., the first principal component\n",
    "        of the data after feature preselection should explain <50% of the variance.\n",
    "    \"\"\"\n",
    "\n",
    "    pca_model = IncrementalPCA(n_components=n_components if n_components is not None else min(X.shape[0],X.shape[-1]), batch_size=batch_size)\n",
    "    pca_model.fit(X)\n",
    "#     print(pca_model.explained_variance_ratio_.cumsum()[0])\n",
    "    return pca_model.explained_variance_ratio_.cumsum()[0] < threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "22674edb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T09:19:56.243120Z",
     "iopub.status.busy": "2024-07-25T09:19:56.242650Z",
     "iopub.status.idle": "2024-07-25T09:19:56.260321Z",
     "shell.execute_reply": "2024-07-25T09:19:56.258960Z"
    },
    "papermill": {
     "duration": 0.035843,
     "end_time": "2024-07-25T09:19:56.263498",
     "exception": false,
     "start_time": "2024-07-25T09:19:56.227655",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectFdr, f_classif\n",
    "from sklearn.utils import resample\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "\n",
    "def parallel_variance_threshold(X, threshold, n_jobs=-1):\n",
    "    sel = VarianceThreshold(threshold)\n",
    "    sel.fit(X)\n",
    "    bool_sels = sel.get_support()\n",
    "    lst_indices_sels = np.where(bool_sels)[0].tolist()\n",
    "    return lst_indices_sels\n",
    "\n",
    "def parallel_fdr_anova_fval(X_chunk, y_chunk, adjusted_p_value_threshold):\n",
    "    sel = SelectFdr(score_func=f_classif, alpha=adjusted_p_value_threshold)\n",
    "    sel.fit(X_chunk, y_chunk)\n",
    "    return sel.scores_, sel.pvalues_\n",
    "\n",
    "def get_indices_feat_sel_var_threshold(X, threshold=0, n_jobs=-1):\n",
    "    return parallel_variance_threshold(X, threshold, n_jobs)\n",
    "\n",
    "def get_indices_feat_sel_fdr_anova_fval_alpha(X, y, adjusted_p_value_threshold=0.05, top_k_score=None, n_jobs=-1):\n",
    "    n_samples, n_features = X.shape\n",
    "    n_chunks = n_jobs if n_jobs > 0 else 1\n",
    "    \n",
    "    chunk_size = n_features // n_chunks\n",
    "    chunks = [(X[:, i*chunk_size:(i+1)*chunk_size], y) for i in range(n_chunks)]\n",
    "    \n",
    "    results = Parallel(n_jobs=n_jobs)(\n",
    "        delayed(parallel_fdr_anova_fval)(X_chunk, y_chunk, adjusted_p_value_threshold) for X_chunk, y_chunk in chunks\n",
    "    )\n",
    "    \n",
    "    f_statistic = np.hstack([res[0] for res in results])\n",
    "    p_values = np.hstack([res[1] for res in results])\n",
    "    \n",
    "    bool_sels = p_values < adjusted_p_value_threshold\n",
    "    lst_indices_sels = np.where(bool_sels)[0]\n",
    "    \n",
    "    f_statistic_desc_indices = np.argsort(f_statistic)[::-1]\n",
    "    f_statistic_desc_indices = np.intersect1d(f_statistic_desc_indices, lst_indices_sels)\n",
    "    \n",
    "    top_k_score = top_k_score if top_k_score is not None else len(f_statistic_desc_indices)\n",
    "    top_idx_by_score = f_statistic_desc_indices[:top_k_score]\n",
    "    \n",
    "    return top_idx_by_score.tolist()\n",
    "\n",
    "def bool_check_exp_var_first_comp_cond(X, threshold=0.5, n_components=None, batch_size=1000):\n",
    "    n_components = n_components if n_components is not None else min(X.shape[0], X.shape[1])\n",
    "    ipca = IncrementalPCA(n_components=n_components, batch_size=batch_size)\n",
    "    ipca.fit(X)\n",
    "    return ipca.explained_variance_ratio_.cumsum()[0] < threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a47ed139",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T09:19:56.290553Z",
     "iopub.status.busy": "2024-07-25T09:19:56.290155Z",
     "iopub.status.idle": "2024-07-25T09:20:28.547765Z",
     "shell.execute_reply": "2024-07-25T09:20:28.546118Z"
    },
    "papermill": {
     "duration": 32.275162,
     "end_time": "2024-07-25T09:20:28.550768",
     "exception": false,
     "start_time": "2024-07-25T09:19:56.275606",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohort: TCGA_GBM\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/TCGA_GBM\n",
      "0               disease_subtypes  disease_subtype_ids\n",
      "sampleID                                             \n",
      "TCGA-02-0001-01        Classical                    0\n",
      "TCGA-02-0003-01        Proneural                    3\n",
      "TCGA-02-0007-01        Proneural                    3\n",
      "TCGA-02-0009-01        Classical                    0\n",
      "TCGA-02-0010-01        Proneural                    3\n",
      "{'Classical': 0, 'Mesenchymal': 1, 'Neural': 2, 'Proneural': 3}\n",
      "\n",
      "Before train/test split: \n",
      "\tTotals 270-[(0, 'Classical', 71), (1, 'Mesenchymal', 81), (2, 'Neural', 46), (3, 'Proneural', 72)]\n",
      "All train: \n",
      "\tTotals 216-(array([0, 1, 2, 3]), array([57, 65, 37, 57]))\n",
      "All test: \n",
      "\tTotals 54-(array([0, 1, 2, 3]), array([14, 16,  9, 15]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 GE\n",
      "len train org: 216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len test idp: 54\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 CNA\n",
      "len train org: 216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len test idp: 54\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Meth\n",
      "len train org: 216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len test idp: 54\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dist train fold: (array([0, 1, 2, 3]), array([43, 49, 27, 43]))\n",
      "dist val fold: (array([0, 1, 2, 3]), array([14, 16, 10, 14]))\n",
      "dist test fold: (array([0, 1, 2, 3]), array([14, 16,  9, 15]))\n",
      "1 GE\n",
      "len train fold: 162\n",
      "len val fold: 54\n",
      "len test fold: 54\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 CNA\n",
      "len train fold: 162\n",
      "len val fold: 54\n",
      "len test fold: 54\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Meth\n",
      "len train fold: 162\n",
      "len val fold: 54\n",
      "len test fold: 54\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 2:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dist train fold: (array([0, 1, 2, 3]), array([43, 49, 28, 42]))\n",
      "dist val fold: (array([0, 1, 2, 3]), array([14, 16,  9, 15]))\n",
      "dist test fold: (array([0, 1, 2, 3]), array([14, 16,  9, 15]))\n",
      "1 GE\n",
      "len train fold: 162\n",
      "len val fold: 54\n",
      "len test fold: 54\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 CNA\n",
      "len train fold: 162\n",
      "len val fold: 54\n",
      "len test fold: 54\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Meth\n",
      "len train fold: 162\n",
      "len val fold: 54\n",
      "len test fold: 54\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 3:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dist train fold: (array([0, 1, 2, 3]), array([43, 48, 28, 43]))\n",
      "dist val fold: (array([0, 1, 2, 3]), array([14, 17,  9, 14]))\n",
      "dist test fold: (array([0, 1, 2, 3]), array([14, 16,  9, 15]))\n",
      "1 GE\n",
      "len train fold: 162\n",
      "len val fold: 54\n",
      "len test fold: 54\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 CNA\n",
      "len train fold: 162\n",
      "len val fold: 54\n",
      "len test fold: 54\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Meth\n",
      "len train fold: 162\n",
      "len val fold: 54\n",
      "len test fold: 54\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 4:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dist train fold: (array([0, 1, 2, 3]), array([42, 49, 28, 43]))\n",
      "dist val fold: (array([0, 1, 2, 3]), array([15, 16,  9, 14]))\n",
      "dist test fold: (array([0, 1, 2, 3]), array([14, 16,  9, 15]))\n",
      "1 GE\n",
      "len train fold: 162\n",
      "len val fold: 54\n",
      "len test fold: 54\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 CNA\n",
      "len train fold: 162\n",
      "len val fold: 54\n",
      "len test fold: 54\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Meth\n",
      "len train fold: 162\n",
      "len val fold: 54\n",
      "len test fold: 54\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import joblib\n",
    "import json \n",
    "\n",
    "for cohort in lst_cohort:\n",
    "    print(f'Cohort: {cohort}')\n",
    "    !mkdir '{cohort}'\n",
    "    %cd '{cohort}'\n",
    "    \n",
    "    # Convert label in name format to label in numeric id format ~ as asc order of name\n",
    "    arr_subtype, arr_num_ex_subtype = np.unique(dct_df[cohort]['labeled']['disease_subtypes'].values, return_counts=True)\n",
    "    \n",
    "    valid_subtypes = arr_subtype[arr_num_ex_subtype >= n_folds]\n",
    "    dct_df[cohort]['labeled'] = dct_df[cohort]['labeled'][dct_df[cohort]['labeled']['disease_subtypes'].isin(valid_subtypes)]\n",
    "    \n",
    "    # Recalculate the unique subtypes and their counts after filtering\n",
    "    arr_subtype, arr_num_ex_subtype = np.unique(dct_df[cohort]['labeled']['disease_subtypes'].values, return_counts=True)\n",
    "    \n",
    "    n_examples = len(dct_df[cohort]['labeled'])\n",
    "    lst_subtype = list(arr_subtype)\n",
    "    lst_num_ex_subtype = list(arr_num_ex_subtype)\n",
    "    dct_index_subtype = {index : subtype for index, subtype in enumerate(lst_subtype)} \n",
    "    dct_subtype_index = {subtype : index for index, subtype in enumerate(lst_subtype)} \n",
    "    dct_df[cohort]['labeled']['disease_subtype_ids'] = dct_df[cohort]['labeled'].replace({'disease_subtypes': dct_subtype_index})['disease_subtypes'].values\n",
    "    print(dct_df[cohort]['labeled'].head())\n",
    "    print(dct_subtype_index)\n",
    "    print()\n",
    "    \n",
    "    print(f\"Before train/test split: \\n\\tTotals {n_examples}-{list(zip(list(dct_index_subtype.keys()), lst_subtype, lst_num_ex_subtype))}\")\n",
    "    y = dct_df[cohort]['labeled']['disease_subtype_ids'].values\n",
    "    X_idx = np.arange(n_examples)\n",
    "\n",
    "    X_train_idx, \\\n",
    "    X_test_idx, \\\n",
    "    y_train, \\\n",
    "    y_test = train_test_split(\n",
    "        X_idx, y, \n",
    "        test_size=0.2, \n",
    "        stratify=y,\n",
    "        shuffle=True,\n",
    "        random_state=RANDOM_STATE_1)\n",
    "    print(f\"All train: \\n\\tTotals {len(y_train)}-{np.unique(y_train, return_counts=True)}\")\n",
    "    print(f\"All test: \\n\\tTotals {len(y_test)}-{np.unique(y_test, return_counts=True)}\")\n",
    "    \n",
    "\n",
    "    train_test_split_org = 'train_test_split_org'\n",
    "    !mkdir '{train_test_split_org}'\n",
    "    pd.DataFrame(y[X_train_idx]).to_csv(f'{train_test_split_org}/labels_tr.csv',\n",
    "                                        index=False, header=False)\n",
    "    pd.DataFrame(y[X_test_idx]).to_csv(f'{train_test_split_org}/labels_te.csv',\n",
    "                                                index=False, header=False) \n",
    "    \n",
    "    dct_name_feat_to_keep = {}\n",
    "    for omic_id, omic in enumerate(lst_omics):\n",
    "        omic_id = omic_id+1\n",
    "        print(omic_id,omic)\n",
    "        \n",
    "        tmp_X_tr = dct_df[cohort][omic].iloc[X_train_idx]\n",
    "        print(f'len train org: {len(tmp_X_tr)}')\n",
    "        \n",
    "        \n",
    "        sel_idx_var = get_indices_feat_sel_var_threshold(tmp_X_tr.values, dct_var_threshold[omic])\n",
    "        tmp_X_tr = tmp_X_tr.iloc[:,sel_idx_var]\n",
    "        \n",
    "        sel_idx_anova_f = get_indices_feat_sel_fdr_anova_fval_alpha(X=tmp_X_tr.values, y=y_train, \n",
    "                                                                    adjusted_p_value_threshold=dct_adjusted_p_value_threshold[omic], \n",
    "                                                                    top_k_score=dct_pre_selection_top[omic])\n",
    "        sel_idx_anova_f = sorted(sel_idx_anova_f) # sorted (return in order of score decreasing, top => idx not in order => sort in order to not change original order)\n",
    "        tmp_X_tr = tmp_X_tr.iloc[:,sel_idx_anova_f]\n",
    "        \n",
    "        assert bool_check_exp_var_first_comp_cond(tmp_X_tr.values, pca_exp_var_first_comp_cond), f'Not pass first component explained threshold with omic {omic}, preselection = {dct_pre_selection_top[omic]}'\n",
    "        \n",
    "        dct_name_feat_to_keep[omic] = tmp_X_tr.columns.tolist()\n",
    "        \n",
    "        tmp_X_te = dct_df[cohort][omic].iloc[X_test_idx] # is exactly independent test set\n",
    "        tmp_X_te = tmp_X_te[dct_name_feat_to_keep[omic]]\n",
    "        unlabeled[cohort][omic] = unlabeled[cohort][omic][dct_name_feat_to_keep[omic]]\n",
    "        print(f'len test idp: {len(tmp_X_te)}')\n",
    "\n",
    "        tmp_X_tr.to_csv(f'{train_test_split_org}/{omic_id}_tr.csv',\n",
    "                                              index=False, header=False)\n",
    "        tmp_X_te.to_csv(f'{train_test_split_org}/{omic_id}_te.csv',\n",
    "                                              index=False, header=False)\n",
    "        \n",
    "        #save features name or genes names\n",
    "        tmp_X_tr.head(0).T.to_csv(f'{train_test_split_org}/{omic_id}_featname.csv',header=False)\n",
    "        \n",
    "    skf = StratifiedKFold(n_splits=n_folds, random_state=RANDOM_STATE_2, shuffle=True)\n",
    "    result_skf = skf.split(X_train_idx,y_train)\n",
    "\n",
    "    for idx_fold, (train_index, val_index) in enumerate(result_skf):\n",
    "        idx_fold = idx_fold+1\n",
    "        print(f'\\nFold {idx_fold}:')\n",
    "        \n",
    "        !mkdir '{idx_fold}'\n",
    "\n",
    "        with open(f\"{idx_fold}/dict_id_omics.json\", \"w\") as outfile: \n",
    "            json.dump(dict_id_omics, outfile)\n",
    "        with open(f\"{idx_fold}/dct_index_subtype.json\", \"w\") as outfile: \n",
    "            json.dump(dct_index_subtype, outfile)\n",
    "\n",
    "        pd.DataFrame(y_train[train_index]).to_csv(f'{idx_fold}/labels_tr.csv',\n",
    "                                            index=False, header=False)\n",
    "        print(f'dist train fold: {np.unique(y_train[train_index],return_counts=True)}')\n",
    "\n",
    "        pd.DataFrame(y_train[val_index]).to_csv(f'{idx_fold}/labels_val.csv',\n",
    "                                                    index=False, header=False)\n",
    "        print(f'dist val fold: {np.unique(y_train[val_index],return_counts=True)}')\n",
    "        \n",
    "        pd.DataFrame(y[X_test_idx]).to_csv(f'{idx_fold}/labels_te.csv',\n",
    "                                                    index=False, header=False)\n",
    "        print(f'dist test fold: {np.unique(y[X_test_idx],return_counts=True)}')\n",
    "\n",
    "        \n",
    "        for omic_id, omic in enumerate(lst_omics):\n",
    "            omic_id = omic_id+1\n",
    "            print(omic_id,omic)\n",
    "            \n",
    "            #save features name or genes names\n",
    "            dct_df[cohort][omic][dct_name_feat_to_keep[omic]].head(0).T.to_csv(f'{idx_fold}/{omic_id}_featname.csv',header=False)\n",
    "\n",
    "            \n",
    "            tmp_X_tr = dct_df[cohort][omic].iloc[X_train_idx[train_index]]\n",
    "            tmp_X_tr = tmp_X_tr[dct_name_feat_to_keep[omic]]\n",
    "            print(f'len train fold: {len(tmp_X_tr)}')\n",
    "            \n",
    "            tmp_X_val = dct_df[cohort][omic].iloc[X_train_idx[val_index]] # is exactly test of kfolds != independent test set\n",
    "            tmp_X_val = tmp_X_val[dct_name_feat_to_keep[omic]]\n",
    "            print(f'len val fold: {len(tmp_X_val)}')\n",
    "            \n",
    "            tmp_X_te = dct_df[cohort][omic].iloc[X_test_idx] # is exactly test of kfolds != independent test set\n",
    "            tmp_X_te = tmp_X_te[dct_name_feat_to_keep[omic]]\n",
    "            print(f'len test fold: {len(tmp_X_te)}')\n",
    "            \n",
    "            if scaler is not None and dict_bool_scale[omic]:\n",
    "                scaler.fit(tmp_X_tr.values)\n",
    "                joblib.dump(scaler, f'{idx_fold}/{scaler.__class__.__name__}_{omic}.pkl')\n",
    "                \n",
    "                tmp_X_tr = pd.DataFrame(scaler.transform(tmp_X_tr.values), index=tmp_X_tr.index, columns=tmp_X_tr.columns)\n",
    "                tmp_X_val = pd.DataFrame(scaler.transform(tmp_X_val.values), index=tmp_X_val.index, columns=tmp_X_val.columns)\n",
    "                tmp_X_te = pd.DataFrame(scaler.transform(tmp_X_te.values), index=tmp_X_te.index, columns=tmp_X_te.columns)\n",
    "                \n",
    "            tmp_X_tr.to_csv(f'{idx_fold}/{omic_id}_tr.csv',\n",
    "                                                  index=False, header=False)\n",
    "            tmp_X_val.to_csv(f'{idx_fold}/{omic_id}_val.csv',\n",
    "                                                  index=False, header=False)\n",
    "            tmp_X_te.to_csv(f'{idx_fold}/{omic_id}_te.csv',\n",
    "                                                  index=False, header=False)\n",
    "            unlabeled[cohort][omic].to_csv(f'{idx_fold}/{omic_id}_unlabeled.csv',\n",
    "                                              index=False, header=False)\n",
    "    %cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "706abd10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T09:20:28.583271Z",
     "iopub.status.busy": "2024-07-25T09:20:28.582389Z",
     "iopub.status.idle": "2024-07-25T09:20:29.787596Z",
     "shell.execute_reply": "2024-07-25T09:20:29.786112Z"
    },
    "papermill": {
     "duration": 1.225092,
     "end_time": "2024-07-25T09:20:29.790784",
     "exception": false,
     "start_time": "2024-07-25T09:20:28.565692",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mTCGA_GBM\u001b[0m/  __notebook__.ipynb  \u001b[01;34mraw_tcga_luad\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e8623375",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T09:20:29.894119Z",
     "iopub.status.busy": "2024-07-25T09:20:29.893603Z",
     "iopub.status.idle": "2024-07-25T09:20:29.904041Z",
     "shell.execute_reply": "2024-07-25T09:20:29.902897Z"
    },
    "papermill": {
     "duration": 0.029552,
     "end_time": "2024-07-25T09:20:29.906735",
     "exception": false,
     "start_time": "2024-07-25T09:20:29.877183",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TCGA_GBM_RS42__MinMaxScaler_GE_True_CNA_False_Meth_True'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_path=\\\n",
    "    f'{cohort}_RS{RANDOM_STATE_1}{\"__\" + scaler.__class__.__name__ if scaler is not None else \"\"}' \\\n",
    "    + '_' \\\n",
    "    + '_'.join([f'{key}_{value}' for key, value in dict_bool_scale.items()])\n",
    "output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b9770a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-23T15:48:33.426550Z",
     "iopub.status.busy": "2024-07-23T15:48:33.426119Z",
     "iopub.status.idle": "2024-07-23T15:48:48.319764Z",
     "shell.execute_reply": "2024-07-23T15:48:48.318879Z",
     "shell.execute_reply.started": "2024-07-23T15:48:33.426495Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": false,
     "start_time": "2024-07-25T09:20:29.921948",
     "status": "running"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "for cohort in lst_cohort:\n",
    "    shutil.make_archive(output_path, 'zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54573320",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5346818,
     "sourceId": 8888614,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5348348,
     "sourceId": 8894207,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5351162,
     "sourceId": 8901209,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5349777,
     "sourceId": 8903214,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5357209,
     "sourceId": 8909768,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5325613,
     "sourceId": 8921293,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5366092,
     "sourceId": 8921700,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30635,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-07-25T09:18:14.178237",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}